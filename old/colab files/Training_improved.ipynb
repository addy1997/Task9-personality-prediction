{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXJDLpNC22PCCBQSsKTyAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addy1997/Task9-personality-prediction/blob/main/Training_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKt2Pgz0hwLu"
      },
      "source": [
        "#import packages\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.constraints import unitnorm\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import random_uniform\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "A-sW8tFphzZB",
        "outputId": "7fc44121-db0c-41b3-db6a-a6a03b7002c0"
      },
      "source": [
        "def get_idx_from_sent(sent, word_idx_map, max_l=51, kernel_size=5):\n",
        "    \"\"\"\n",
        "    Transforms sentence into a list of indices. Pad with zeroes.\n",
        "    \"\"\"\n",
        "    x = []\n",
        "    pad = kernel_size - 1\n",
        "    for i in range(pad):\n",
        "        x.append(0)\n",
        "    words = sent.split()\n",
        "    for word in words:\n",
        "        if word in word_idx_map:\n",
        "            x.append(word_idx_map[word])\n",
        "    while len(x) < max_l+2*pad:\n",
        "        x.append(0)\n",
        "    return x\n",
        "\n",
        "def make_idx_data(revs, word_idx_map, max_l=51, kernel_size=5):\n",
        "    \"\"\"\n",
        "    Transforms sentences into a 2-d matrix.\n",
        "    \"\"\"\n",
        "    train, val, test = [], [], []\n",
        "    for rev in revs:\n",
        "        sent = get_idx_from_sent(rev['text'], word_idx_map, max_l, kernel_size)\n",
        "        sent.append(rev['y'])\n",
        "        if rev['split'] == 1:\n",
        "            train.append(sent)\n",
        "        elif rev['split'] == 0:\n",
        "            val.append(sent)\n",
        "    train = np.array(train, dtype=np.int)\n",
        "    val = np.array(val, dtype=np.int)\n",
        "    return [train, val]\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "file = files.upload()\n",
        "\n",
        "\n",
        "print (\"loading data...\")\n",
        "\n",
        "with open(\"imdb-train-val-testN.pickle\", 'rb') as f:\n",
        "    x = pickle.load(f, encoding='latin')\n",
        "revs, W, word_idx_map, vocab = x[0], x[1], x[2], x[3]\n",
        "print (\"data loaded!\")\n",
        "\n",
        "datasets = make_idx_data(revs, word_idx_map, max_l=2721,kernel_size=5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63fa7d15-ad53-4fdb-b1a0-6b2558e0b3eb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63fa7d15-ad53-4fdb-b1a0-6b2558e0b3eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving imdb-train-val-testN.pickle to imdb-train-val-testN.pickle\n",
            "loading data...\n",
            "data loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpKLSkKfR6lA",
        "outputId": "2d71a197-9c08-4c6a-966b-19a9f0178021"
      },
      "source": [
        "# Train data preparation\n",
        "N = datasets[0].shape[0]\n",
        "conv_input_width = W.shape[1]\n",
        "conv_input_height = int(datasets[0].shape[1]-1)\n",
        "\n",
        "# For each word write a word index (not vector) to X tensor\n",
        "train_X = np.zeros((N, conv_input_height), dtype=np.int)\n",
        "train_Y = np.zeros((N, 2), dtype=np.int)\n",
        "for i in range(N):\n",
        "    for j in range(conv_input_height):\n",
        "        train_X[i, j] = datasets[0][i, j]\n",
        "    \n",
        "print ('train_X.shape = {}'.format(train_X.shape))\n",
        "print ('train_Y.shape = {}'.format(train_Y.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X.shape = (1997, 2729)\n",
            "train_Y.shape = (1997, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkLESZ7Z9mi2"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/addy1997/Task9-personality-prediction/main/essays.csv'\n",
        "data_train = pd.read_csv(url, encoding='latin')\n",
        "for i in range(N):\n",
        "    train_Y[i,data_train.iloc[i,3]] = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avmdnj9Y9rzX",
        "outputId": "4a39431f-6f3a-4c39-b88b-829c5bf87607"
      },
      "source": [
        "print(train_X.shape)\n",
        "print(train_Y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1997, 2729)\n",
            "[[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLFl5AW6ZX_E",
        "outputId": "fd4a5b6c-3ff3-41e5-fba7-2f0d6918e6d0"
      },
      "source": [
        "# Validation data preparation\n",
        "Nv = datasets[1].shape[0]\n",
        "\n",
        "# For each word write a word index (not vector) to X tensor\n",
        "val_X = np.zeros((Nv, conv_input_height), dtype=np.int)\n",
        "val_Y = np.zeros((Nv, 2), dtype=np.int)\n",
        "for i in range(Nv):\n",
        "    for j in range(conv_input_height):\n",
        "        val_X[i, j] = datasets[1][i, j]\n",
        "    \n",
        "print ('val_X.shape = {}'.format(val_X.shape))\n",
        "print ('val_Y.shape = {}'.format(val_Y.shape))\n",
        "for i in range(Nv):\n",
        "    val_Y[i,data_train.iloc[i,3]] = 1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val_X.shape = (470, 2729)\n",
            "val_Y.shape = (470, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-fGOcjnTAYK"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Atin17/Personality_Prediction_using_Twitter/master/essays.csv'\n",
        "data_train = pd.read_csv(url, encoding='latin')\n",
        "for i in range(N):\n",
        "    train_Y[i,data_train.iloc[i,3]] = 1\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2cDTz-gTDeZ",
        "outputId": "764974a7-8b0f-4116-9416-fed9010b93db"
      },
      "source": [
        "print(train_X.shape)\n",
        "print(train_Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1997, 2729)\n",
            "[[0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJyh0cY_jHvx"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras.constraints import UnitNorm\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.initializers import random_uniform\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "backend.set_image_data_format('channels_first')\n",
        "\n",
        "# Number of feature maps (outputs of convolutional layer)\n",
        "N_fm = 300\n",
        "# kernel size of convolutional layer\n",
        "kernel_size = 8\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVmacoUbZjsr"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras.constraints import UnitNorm\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.initializers import random_uniform\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "backend.set_image_data_format('channels_first')\n",
        "\n",
        "# Number of feature maps (outputs of convolutional layer)\n",
        "N_fm = 300\n",
        "# kernel size of convolutional layer\n",
        "kernel_size = 8\n",
        "\n",
        "model = Sequential()\n",
        "# Embedding layer (lookup table of trainable word vectors)\n",
        "model.add(Embedding(input_dim=W.shape[0], \n",
        "                    output_dim=W.shape[1], \n",
        "                    input_length=conv_input_height,\n",
        "                    weights=[W]))\n",
        "# Reshape word vectors from Embedding to tensor format suitable for Convolutional layer\n",
        "model.add(Reshape((1, conv_input_height, conv_input_width)))\n",
        "\n",
        "# first convolutional layer\n",
        "model.add(Convolution2D(N_fm, \n",
        "                        kernel_size, \n",
        "                        conv_input_width, \n",
        "                        padding='same', \n",
        "                        kernel_regularizer=l2(0.0001)))\n",
        "# ReLU activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# aggregate data in every feature map to scalar using MAX operation\n",
        "model.add(MaxPooling2D(pool_size=(conv_input_height-kernel_size+1, 1), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "# Inner Product layer (as in regular neural network, but without non-linear activation function)\n",
        "model.add(Dense(2))\n",
        "# SoftMax activation; actually, Dense+SoftMax works as Multinomial Logistic Regression\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Custom optimizers could be used, though right now standard adadelta is employed\n",
        "opt = Adadelta(lr=1.0, rho=0.95, epsilon=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwF1uSC79zMW",
        "outputId": "4d42d54f-f570-4000-e809-49c5ce498ded"
      },
      "source": [
        "model.weights"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_2/embeddings:0' shape=(30395, 300) dtype=float32, numpy=\n",
              " array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.00714111,  0.00448608,  0.02062988, ...,  0.01416016,\n",
              "         -0.06689453, -0.15136719],\n",
              "        [ 0.16894531,  0.390625  ,  0.08642578, ...,  0.01123047,\n",
              "         -0.02941895,  0.15722656],\n",
              "        ...,\n",
              "        [-0.18699868,  0.16601674,  0.0797045 , ...,  0.21439357,\n",
              "         -0.18920986, -0.02926444],\n",
              "        [ 0.14319344, -0.17904061,  0.16860904, ..., -0.00733663,\n",
              "          0.17451356,  0.11404853],\n",
              "        [ 0.07610573, -0.07467093,  0.11883443, ..., -0.11819206,\n",
              "         -0.13819139,  0.05161416]], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_2/kernel:0' shape=(8, 8, 1, 300) dtype=float32, numpy=\n",
              " array([[[[ 1.41785853e-02,  1.17775686e-02, -4.67845425e-03, ...,\n",
              "           -1.56073961e-02,  8.14453699e-03,  1.87661499e-04]],\n",
              " \n",
              "         [[-2.76058167e-03,  1.74114518e-02, -2.02888716e-03, ...,\n",
              "           -6.31221943e-03, -1.19314846e-02, -1.24725876e-02]],\n",
              " \n",
              "         [[ 1.50131956e-02, -1.66874137e-02,  6.22818805e-03, ...,\n",
              "           -1.70550551e-02,  1.69838779e-02,  1.01645160e-02]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-1.73489656e-02, -1.31488033e-02,  1.64240450e-02, ...,\n",
              "            7.41869584e-03,  1.48371793e-02, -9.16163344e-03]],\n",
              " \n",
              "         [[-1.15647689e-02,  8.36539268e-03, -4.07871231e-03, ...,\n",
              "            8.32989812e-03, -5.56558836e-03, -1.68759767e-02]],\n",
              " \n",
              "         [[-1.71668027e-02,  7.83347525e-03, -2.32741423e-03, ...,\n",
              "           -1.56301390e-02, -1.57240033e-03,  1.37520619e-02]]],\n",
              " \n",
              " \n",
              "        [[[-1.07533643e-02, -7.81392306e-03, -2.38011964e-03, ...,\n",
              "            1.29576772e-03,  4.59959358e-03,  1.10902824e-02]],\n",
              " \n",
              "         [[ 4.10373509e-03,  3.07707116e-03,  1.13104768e-02, ...,\n",
              "           -1.85532123e-03, -1.18936701e-02,  4.94545698e-03]],\n",
              " \n",
              "         [[ 9.90210846e-03,  1.26947835e-02, -1.57313123e-02, ...,\n",
              "            1.42131634e-02,  5.35636581e-03, -8.57023522e-04]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-1.59442127e-02, -1.05539337e-02,  9.74184647e-03, ...,\n",
              "            6.17555343e-03,  1.44735724e-02, -1.65888704e-02]],\n",
              " \n",
              "         [[-1.12066492e-02, -1.73232574e-02,  1.01652443e-02, ...,\n",
              "            1.57380030e-02,  5.50249405e-03, -9.01195407e-03]],\n",
              " \n",
              "         [[-1.57228038e-02,  1.63817964e-02,  5.07082045e-03, ...,\n",
              "            2.39849463e-03,  1.40034705e-02, -1.32899210e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 1.17100179e-02,  1.59485750e-02,  1.29973106e-02, ...,\n",
              "            8.13322142e-04, -7.38338474e-03, -4.39389702e-03]],\n",
              " \n",
              "         [[-2.17697676e-03, -5.21260593e-03, -7.75970239e-03, ...,\n",
              "           -1.61494240e-02,  1.60870254e-02,  1.09537691e-03]],\n",
              " \n",
              "         [[ 1.72405615e-02,  4.15961258e-03,  2.23199278e-03, ...,\n",
              "           -9.92972404e-03,  1.65394545e-02, -1.11200633e-02]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-1.21108834e-02,  1.41142644e-02, -1.31456684e-02, ...,\n",
              "           -6.47689123e-03, -6.53110258e-03,  3.75250727e-03]],\n",
              " \n",
              "         [[-8.98524374e-03,  5.90118766e-03,  3.35751288e-03, ...,\n",
              "            1.22417118e-02, -9.08507034e-03, -1.71985384e-02]],\n",
              " \n",
              "         [[ 1.22016892e-02, -1.02153663e-02, -1.64076928e-02, ...,\n",
              "            1.31378081e-02, -1.49445608e-02,  1.30069796e-02]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[ 1.58649981e-02,  2.72894464e-03, -7.53784552e-04, ...,\n",
              "            3.22587416e-03, -1.49417752e-02,  3.84338200e-05]],\n",
              " \n",
              "         [[-1.23365577e-02, -2.35985965e-03, -1.33296624e-02, ...,\n",
              "           -2.42874771e-03,  1.22955963e-02,  1.69916004e-02]],\n",
              " \n",
              "         [[-4.13468294e-03, -1.74155943e-02, -9.42721963e-05, ...,\n",
              "            8.65842402e-03, -7.20426440e-04, -9.72133130e-05]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ 6.13171607e-04,  1.48982704e-02, -4.76521160e-03, ...,\n",
              "            9.42708366e-03, -1.48094939e-02,  1.29866973e-03]],\n",
              " \n",
              "         [[ 1.62992552e-02, -1.27031840e-03,  1.67528689e-02, ...,\n",
              "            5.15627675e-03, -5.46700228e-03,  1.72494315e-02]],\n",
              " \n",
              "         [[-2.44690385e-03,  8.78495350e-03,  3.66402417e-03, ...,\n",
              "           -3.25765181e-03, -1.39280315e-02, -1.32462792e-02]]],\n",
              " \n",
              " \n",
              "        [[[-3.20038106e-03,  1.69825777e-02,  1.08317416e-02, ...,\n",
              "           -1.13946386e-03, -6.49981201e-04,  1.85573660e-03]],\n",
              " \n",
              "         [[ 2.22179666e-03,  1.06929541e-02, -6.16578758e-03, ...,\n",
              "           -1.40049653e-02, -8.25664587e-03, -1.62863806e-02]],\n",
              " \n",
              "         [[ 1.21067632e-02,  4.17174771e-03,  1.75566524e-02, ...,\n",
              "            2.22823955e-03, -1.74872391e-03, -7.26208556e-03]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ 5.05401939e-03, -7.17496593e-03, -9.44895856e-03, ...,\n",
              "            1.59349851e-02, -1.84746459e-03,  1.40933096e-02]],\n",
              " \n",
              "         [[-1.48129528e-02,  7.25655258e-03,  1.68745331e-02, ...,\n",
              "           -9.84480884e-03, -1.18709914e-03, -1.07116327e-02]],\n",
              " \n",
              "         [[ 1.47261694e-02,  8.75538215e-03, -1.25123169e-02, ...,\n",
              "           -1.51496092e-02, -8.74427799e-03, -1.30964350e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 1.41135864e-02, -1.03506306e-02, -1.08116698e-02, ...,\n",
              "           -1.57903340e-02,  1.67165920e-02, -1.72755178e-02]],\n",
              " \n",
              "         [[ 1.53673887e-02, -1.26146302e-02,  2.72062980e-03, ...,\n",
              "            1.20607205e-03,  1.33487731e-02,  1.68708153e-02]],\n",
              " \n",
              "         [[-1.26744341e-02,  8.13673064e-03,  4.92251106e-03, ...,\n",
              "           -1.16876494e-02,  1.67216659e-02, -1.29411500e-02]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-8.35829135e-03, -1.62637047e-02, -3.97326425e-04, ...,\n",
              "            1.64142996e-02, -5.19188307e-03, -2.69735698e-03]],\n",
              " \n",
              "         [[ 4.33817878e-03,  1.31159965e-02,  3.41537595e-03, ...,\n",
              "           -3.13514844e-04, -1.46975489e-02,  1.58974677e-02]],\n",
              " \n",
              "         [[ 1.52527615e-02,  8.96423496e-03, -1.60712805e-02, ...,\n",
              "           -1.20490091e-02,  8.55295919e-03, -1.39065478e-02]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_2/bias:0' shape=(300,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(300, 2) dtype=float32, numpy=\n",
              " array([[-0.05659268, -0.12407631],\n",
              "        [-0.08065496, -0.13654958],\n",
              "        [-0.04715453,  0.06155287],\n",
              "        [ 0.1360676 , -0.12884535],\n",
              "        [-0.04390873,  0.1268374 ],\n",
              "        [-0.11367553, -0.02137995],\n",
              "        [-0.00765157,  0.08778003],\n",
              "        [ 0.06265463,  0.00476605],\n",
              "        [ 0.11403659, -0.12417611],\n",
              "        [-0.10320888, -0.09151442],\n",
              "        [-0.12837578,  0.12221646],\n",
              "        [ 0.06106576, -0.05673984],\n",
              "        [ 0.03784974,  0.04001713],\n",
              "        [ 0.05514027, -0.04502548],\n",
              "        [-0.09385435,  0.07485016],\n",
              "        [ 0.06029804,  0.04810281],\n",
              "        [ 0.10826273,  0.13929412],\n",
              "        [-0.02390722, -0.04534446],\n",
              "        [-0.04289744, -0.02133801],\n",
              "        [ 0.03768933,  0.04443741],\n",
              "        [ 0.02920377,  0.07498764],\n",
              "        [ 0.03946789, -0.11760117],\n",
              "        [ 0.00318763,  0.12520292],\n",
              "        [-0.0413171 , -0.04889547],\n",
              "        [ 0.1135428 ,  0.07357962],\n",
              "        [-0.02707899,  0.07148714],\n",
              "        [ 0.11081156,  0.03321245],\n",
              "        [-0.10311892, -0.07632269],\n",
              "        [-0.07961036,  0.09465997],\n",
              "        [ 0.13412905,  0.03647634],\n",
              "        [-0.04502958,  0.11135727],\n",
              "        [ 0.0159615 ,  0.0639216 ],\n",
              "        [ 0.05199495, -0.09551837],\n",
              "        [ 0.01959568,  0.13290918],\n",
              "        [-0.12091116, -0.13595775],\n",
              "        [-0.06590188,  0.09443545],\n",
              "        [-0.04452761,  0.04887487],\n",
              "        [ 0.10652277,  0.08483322],\n",
              "        [-0.07635462, -0.05422913],\n",
              "        [ 0.09311788, -0.13377355],\n",
              "        [-0.10365006,  0.03263602],\n",
              "        [ 0.02132815, -0.13757616],\n",
              "        [-0.11243935,  0.00418837],\n",
              "        [-0.08526145, -0.08968408],\n",
              "        [-0.05938631,  0.0392891 ],\n",
              "        [ 0.06838456,  0.14038235],\n",
              "        [ 0.11552602,  0.06047086],\n",
              "        [ 0.01626453,  0.06221668],\n",
              "        [ 0.03488024,  0.13351154],\n",
              "        [-0.11053774,  0.00552997],\n",
              "        [ 0.11738899,  0.04060823],\n",
              "        [-0.02702485, -0.07304822],\n",
              "        [-0.04710127, -0.06089104],\n",
              "        [-0.03461264,  0.0658603 ],\n",
              "        [ 0.0044298 , -0.13876829],\n",
              "        [-0.07809827, -0.11363234],\n",
              "        [-0.09716649,  0.11822155],\n",
              "        [ 0.08467446,  0.05147615],\n",
              "        [ 0.00779884,  0.00066885],\n",
              "        [-0.05603231, -0.07535787],\n",
              "        [-0.13696289,  0.05018096],\n",
              "        [-0.12984896,  0.10023193],\n",
              "        [ 0.08240658, -0.14049713],\n",
              "        [ 0.12243021, -0.00559467],\n",
              "        [ 0.1075877 ,  0.03598727],\n",
              "        [ 0.11146653,  0.01079689],\n",
              "        [ 0.01772052, -0.01513048],\n",
              "        [-0.05787631, -0.0264055 ],\n",
              "        [-0.12229   , -0.09982664],\n",
              "        [ 0.1156927 ,  0.06657866],\n",
              "        [ 0.11034235, -0.12523614],\n",
              "        [ 0.08730833,  0.01146218],\n",
              "        [ 0.10887711,  0.13396785],\n",
              "        [-0.09151825, -0.03666191],\n",
              "        [ 0.11153084,  0.04732946],\n",
              "        [ 0.08124883,  0.12008163],\n",
              "        [-0.06314114,  0.03048261],\n",
              "        [ 0.11861843,  0.03795815],\n",
              "        [-0.12009427, -0.01227994],\n",
              "        [ 0.10679504,  0.0186431 ],\n",
              "        [-0.13474627,  0.04070339],\n",
              "        [-0.03364459,  0.04285234],\n",
              "        [-0.13840283,  0.02329281],\n",
              "        [-0.02094562,  0.1382305 ],\n",
              "        [-0.02488374, -0.10747522],\n",
              "        [ 0.06204604, -0.10232122],\n",
              "        [ 0.01811852, -0.00355414],\n",
              "        [ 0.1342791 ,  0.07279755],\n",
              "        [-0.04008474,  0.13660377],\n",
              "        [-0.05582022,  0.12704128],\n",
              "        [ 0.09050195, -0.09233201],\n",
              "        [-0.08266367, -0.09010826],\n",
              "        [-0.04598334,  0.02455017],\n",
              "        [ 0.09451896,  0.02608904],\n",
              "        [-0.00952794,  0.13446948],\n",
              "        [ 0.13154194, -0.09650758],\n",
              "        [ 0.12756526, -0.08666614],\n",
              "        [-0.0992004 ,  0.00558841],\n",
              "        [-0.02653055, -0.06782093],\n",
              "        [-0.03818892,  0.12039366],\n",
              "        [-0.10604274,  0.07142557],\n",
              "        [-0.01539274,  0.04082696],\n",
              "        [ 0.09921525, -0.13956596],\n",
              "        [ 0.02411903, -0.1204921 ],\n",
              "        [ 0.00143348, -0.09213065],\n",
              "        [ 0.12442523, -0.00582805],\n",
              "        [ 0.13530326, -0.01842527],\n",
              "        [-0.11074834,  0.07170258],\n",
              "        [ 0.1235339 ,  0.01702851],\n",
              "        [-0.05967865,  0.05699211],\n",
              "        [ 0.09834114, -0.08142258],\n",
              "        [-0.0537323 ,  0.01183991],\n",
              "        [ 0.1032069 ,  0.06988351],\n",
              "        [-0.00768964,  0.05593149],\n",
              "        [ 0.13073674,  0.00712289],\n",
              "        [-0.04733412, -0.08035177],\n",
              "        [ 0.12463939, -0.08278969],\n",
              "        [-0.09651272, -0.06095479],\n",
              "        [-0.00842422,  0.10945314],\n",
              "        [-0.1214798 ,  0.06621632],\n",
              "        [ 0.1407263 ,  0.07977039],\n",
              "        [ 0.08492859,  0.13675213],\n",
              "        [-0.12301628, -0.13508475],\n",
              "        [-0.13005851,  0.02925624],\n",
              "        [ 0.09634836, -0.09932216],\n",
              "        [-0.10527267, -0.07017817],\n",
              "        [-0.01619872, -0.04328511],\n",
              "        [-0.05600555, -0.00325333],\n",
              "        [ 0.01592524,  0.10709275],\n",
              "        [-0.08188425,  0.01868804],\n",
              "        [ 0.04810484, -0.10311015],\n",
              "        [-0.03993859, -0.10418802],\n",
              "        [-0.12332569,  0.01664528],\n",
              "        [ 0.1363878 ,  0.09263793],\n",
              "        [-0.02616636, -0.11855373],\n",
              "        [ 0.03149243, -0.11614343],\n",
              "        [-0.11128549, -0.0348141 ],\n",
              "        [-0.05812627,  0.04111846],\n",
              "        [-0.12893249,  0.05081761],\n",
              "        [ 0.06636581, -0.13783412],\n",
              "        [ 0.03169668, -0.10067925],\n",
              "        [ 0.13136452, -0.02663489],\n",
              "        [ 0.02657145,  0.00434957],\n",
              "        [ 0.12200511,  0.02220866],\n",
              "        [-0.0249943 ,  0.10707018],\n",
              "        [ 0.07938462, -0.13532594],\n",
              "        [ 0.02484952, -0.08086221],\n",
              "        [ 0.11498675, -0.13165034],\n",
              "        [-0.13567977,  0.12393084],\n",
              "        [ 0.04742119,  0.03800772],\n",
              "        [ 0.13769355, -0.03480446],\n",
              "        [ 0.08964837,  0.11907911],\n",
              "        [-0.10135318, -0.0317204 ],\n",
              "        [-0.1321962 , -0.08104902],\n",
              "        [ 0.06330958, -0.08692093],\n",
              "        [-0.1292635 , -0.09727453],\n",
              "        [ 0.01559073, -0.08012056],\n",
              "        [ 0.09539083,  0.01184303],\n",
              "        [ 0.01128027,  0.00302841],\n",
              "        [-0.09533367, -0.11845122],\n",
              "        [ 0.10647875,  0.11652622],\n",
              "        [ 0.05370763,  0.07348318],\n",
              "        [-0.12217776, -0.00867224],\n",
              "        [ 0.11686322, -0.09631015],\n",
              "        [ 0.09095334, -0.00180392],\n",
              "        [ 0.13292876,  0.02574334],\n",
              "        [ 0.07723226,  0.10199326],\n",
              "        [-0.06153012, -0.02045485],\n",
              "        [ 0.08632562, -0.05618897],\n",
              "        [ 0.12132242,  0.04392993],\n",
              "        [-0.14022698, -0.12267414],\n",
              "        [-0.11879145,  0.05475505],\n",
              "        [ 0.1042396 ,  0.01488569],\n",
              "        [-0.04301529,  0.04102762],\n",
              "        [-0.00267962,  0.09446913],\n",
              "        [ 0.09556229,  0.08843181],\n",
              "        [ 0.13598701, -0.00278053],\n",
              "        [-0.12336151,  0.07603855],\n",
              "        [ 0.04893708,  0.078196  ],\n",
              "        [ 0.04576515,  0.05062687],\n",
              "        [ 0.03403889, -0.11277685],\n",
              "        [-0.09025139, -0.12474015],\n",
              "        [ 0.03176109, -0.08012728],\n",
              "        [-0.13697809, -0.0766772 ],\n",
              "        [ 0.12141967,  0.07167499],\n",
              "        [ 0.07682042,  0.07455601],\n",
              "        [ 0.01216474, -0.13797812],\n",
              "        [ 0.02929766, -0.10053848],\n",
              "        [-0.01180305, -0.05119645],\n",
              "        [ 0.08466025, -0.11517491],\n",
              "        [ 0.0343242 ,  0.11394376],\n",
              "        [ 0.11650932,  0.1277881 ],\n",
              "        [-0.09034753, -0.09645445],\n",
              "        [-0.00929697,  0.11426863],\n",
              "        [ 0.08293289, -0.06543775],\n",
              "        [-0.10311149,  0.09711346],\n",
              "        [-0.0081525 , -0.0595869 ],\n",
              "        [-0.03817265,  0.03194676],\n",
              "        [-0.02788872, -0.0324157 ],\n",
              "        [-0.05528199,  0.07916549],\n",
              "        [-0.09930031, -0.01769441],\n",
              "        [ 0.13993534,  0.12546253],\n",
              "        [-0.04288826, -0.01005313],\n",
              "        [ 0.06260002,  0.07540996],\n",
              "        [ 0.1377731 ,  0.02777685],\n",
              "        [ 0.06348537, -0.02520282],\n",
              "        [ 0.00276124,  0.01655367],\n",
              "        [ 0.0614832 ,  0.04061934],\n",
              "        [ 0.1334635 ,  0.0893494 ],\n",
              "        [-0.13317655,  0.05146375],\n",
              "        [ 0.04928496,  0.02800825],\n",
              "        [-0.11473861, -0.05583877],\n",
              "        [-0.01409347,  0.05464193],\n",
              "        [ 0.13863844, -0.07259884],\n",
              "        [-0.04802059,  0.0830349 ],\n",
              "        [ 0.01356952, -0.10626125],\n",
              "        [ 0.08759631, -0.05435743],\n",
              "        [ 0.00306782,  0.10711053],\n",
              "        [ 0.03361273,  0.1215165 ],\n",
              "        [-0.08179647, -0.11169018],\n",
              "        [ 0.02063169, -0.08508062],\n",
              "        [ 0.06120989, -0.03743625],\n",
              "        [-0.12915406,  0.05849983],\n",
              "        [-0.13561544, -0.05604689],\n",
              "        [ 0.03444622, -0.00154109],\n",
              "        [-0.05808286, -0.1119896 ],\n",
              "        [ 0.05622059,  0.12717867],\n",
              "        [-0.04456505, -0.02313533],\n",
              "        [-0.05564842,  0.04291569],\n",
              "        [ 0.00102262, -0.10108198],\n",
              "        [-0.0611084 ,  0.11240995],\n",
              "        [ 0.05619536,  0.02759376],\n",
              "        [-0.04376829,  0.12013343],\n",
              "        [-0.06079197, -0.09526471],\n",
              "        [ 0.03872466, -0.07386   ],\n",
              "        [-0.05411161, -0.02971085],\n",
              "        [ 0.03335585,  0.05400531],\n",
              "        [-0.09712955,  0.08748366],\n",
              "        [-0.05361509,  0.09060842],\n",
              "        [ 0.06428057,  0.03261408],\n",
              "        [ 0.02978382,  0.07634676],\n",
              "        [ 0.10315152, -0.00193636],\n",
              "        [-0.12300184,  0.04892656],\n",
              "        [ 0.03980471,  0.05995381],\n",
              "        [-0.03389956, -0.09702521],\n",
              "        [-0.02571386, -0.02496177],\n",
              "        [ 0.002332  , -0.09489428],\n",
              "        [ 0.13118732,  0.10223727],\n",
              "        [-0.13484685, -0.13622952],\n",
              "        [-0.07783719,  0.06960915],\n",
              "        [-0.03873888,  0.08480152],\n",
              "        [-0.0881017 ,  0.06479689],\n",
              "        [ 0.05402346, -0.13572218],\n",
              "        [ 0.00095417,  0.09234932],\n",
              "        [ 0.0215387 ,  0.08163369],\n",
              "        [ 0.13809964, -0.13302508],\n",
              "        [-0.12096167, -0.05308028],\n",
              "        [-0.00432925, -0.10877569],\n",
              "        [ 0.02870671, -0.12986706],\n",
              "        [-0.09308101, -0.00146753],\n",
              "        [-0.12799768,  0.10971564],\n",
              "        [ 0.09625755,  0.07566969],\n",
              "        [ 0.11767745, -0.05362083],\n",
              "        [-0.04966386, -0.0144431 ],\n",
              "        [-0.06368817, -0.113026  ],\n",
              "        [ 0.13619468,  0.13138315],\n",
              "        [-0.12912636,  0.09276643],\n",
              "        [-0.01149648,  0.0097166 ],\n",
              "        [ 0.07458434,  0.05831994],\n",
              "        [ 0.09952937, -0.05775073],\n",
              "        [ 0.02948041, -0.0939438 ],\n",
              "        [ 0.0794761 ,  0.02636261],\n",
              "        [-0.10371858, -0.01308462],\n",
              "        [-0.12590641, -0.01516595],\n",
              "        [ 0.01007517,  0.12379798],\n",
              "        [ 0.02405834, -0.09646803],\n",
              "        [-0.03656613, -0.07192754],\n",
              "        [-0.03128824, -0.00671652],\n",
              "        [-0.05941229, -0.12289709],\n",
              "        [-0.13574994,  0.04345986],\n",
              "        [ 0.06819838, -0.0514615 ],\n",
              "        [-0.13568172, -0.10857194],\n",
              "        [-0.05698744,  0.10599616],\n",
              "        [ 0.12596443,  0.07691112],\n",
              "        [ 0.00192025, -0.00838159],\n",
              "        [-0.11095508,  0.10180834],\n",
              "        [ 0.09977388,  0.02890569],\n",
              "        [ 0.06780598, -0.01901374],\n",
              "        [ 0.03664051, -0.14054286],\n",
              "        [ 0.10065001, -0.05557853],\n",
              "        [ 0.00928053,  0.04364218],\n",
              "        [-0.13458638,  0.03196129],\n",
              "        [-0.07870933, -0.13565627],\n",
              "        [ 0.10211915,  0.01946083],\n",
              "        [-0.05260094,  0.09460261],\n",
              "        [-0.05354948, -0.13323928],\n",
              "        [-0.0653495 ,  0.06897061],\n",
              "        [ 0.1065172 , -0.04035836],\n",
              "        [ 0.01316418,  0.09048942],\n",
              "        [-0.0376562 , -0.02940162]], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwsCz2lsmOdl",
        "outputId": "fdb9f88d-0826-4c13-e02c-e4bf93cc32b8"
      },
      "source": [
        "model.fit(x=train_X,y=train_Y,batch_size=32,epochs=15,verbose=1, validation_data=(val_X,val_Y))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0240 - accuracy: 0.9980 - val_loss: 3.0697 - val_accuracy: 0.5191\n",
            "Epoch 2/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0244 - accuracy: 0.9970 - val_loss: 3.0645 - val_accuracy: 0.5149\n",
            "Epoch 3/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0242 - accuracy: 0.9965 - val_loss: 3.0822 - val_accuracy: 0.5255\n",
            "Epoch 4/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0210 - accuracy: 0.9980 - val_loss: 3.1197 - val_accuracy: 0.5191\n",
            "Epoch 5/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0215 - accuracy: 0.9975 - val_loss: 3.1563 - val_accuracy: 0.5213\n",
            "Epoch 6/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 3.2259 - val_accuracy: 0.5255\n",
            "Epoch 7/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0195 - accuracy: 0.9980 - val_loss: 3.2353 - val_accuracy: 0.5234\n",
            "Epoch 8/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0188 - accuracy: 0.9985 - val_loss: 3.2744 - val_accuracy: 0.5234\n",
            "Epoch 9/15\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 3.2636 - val_accuracy: 0.5319\n",
            "Epoch 10/15\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.0175 - accuracy: 0.9985 - val_loss: 3.2495 - val_accuracy: 0.5404\n",
            "Epoch 11/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0167 - accuracy: 0.9995 - val_loss: 3.2797 - val_accuracy: 0.5277\n",
            "Epoch 12/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0170 - accuracy: 0.9985 - val_loss: 3.2754 - val_accuracy: 0.5298\n",
            "Epoch 13/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0174 - accuracy: 0.9980 - val_loss: 3.2716 - val_accuracy: 0.5426\n",
            "Epoch 14/15\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0160 - accuracy: 0.9985 - val_loss: 3.2949 - val_accuracy: 0.5298\n",
            "Epoch 15/15\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 3.3132 - val_accuracy: 0.5191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c4e31c240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}